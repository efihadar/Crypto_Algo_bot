# ml_system/per_symbol_model.py
"""
ðŸŽ¯ Professional Per-Symbol Model Manager
Manages separate ML models for each trading symbol with fallback to global model.
Production-ready with comprehensive monitoring and error handling.
"""

import pandas as pd
from typing import Dict, Optional, Any, List, Tuple
from loguru import logger
import threading
import time
from datetime import datetime

# Import local components
from .config import ml_config
from .model_training import ModelTrainer
from .feature_engineering import feature_engineer
from .drift_detector import DataDriftDetector
from .ml_db import get_ml_db

class PerSymbolModelManager:
    """
    Professional manager for per-symbol ML models with comprehensive monitoring
    
    Features:
    - Separate models for each symbol
    - Fallback to global model
    - Automatic retraining based on data drift
    - Performance monitoring
    - Thread-safe operations
    """
    
    def __init__(self):
        """Initialize per-symbol model manager"""
        self.models: Dict[str, Any] = {}  # Symbol -> Model mapping
        self.model_metadata: Dict[str, Dict] = {}  # Symbol -> Metadata
        self.global_model: Optional[Any] = None
        self.global_metadata: Optional[Dict] = None
        
        # Configuration
        self.min_samples_per_symbol = getattr(ml_config, 'min_samples_per_symbol', 50)
        self.retrain_threshold = getattr(ml_config, 'retrain_threshold', 0.2)  # Drift threshold
        self.max_models = getattr(ml_config, 'max_per_symbol_models', 20)  # Limit total models
        
        # Initialize components
        self.model_trainer = ModelTrainer()
        self.drift_detectors: Dict[str, DataDriftDetector] = {}
        self.db = get_ml_db()
        
        # Thread safety
        self._lock = threading.RLock()  # Reentrant lock for nested calls
        self._training_lock = threading.Lock()  # Separate lock for training operations
        
        # Performance tracking
        self.prediction_stats: Dict[str, Dict] = {}
        self.last_retrain_check: Dict[str, datetime] = {}
        
        logger.info(f"ðŸŽ¯ Per-Symbol Model Manager initialized with min_samples={self.min_samples_per_symbol}")
    
    def train_symbol_model(self, symbol: str, data: pd.DataFrame) -> bool:
        """
        Train model specific to symbol with comprehensive validation
        
        Args:
            symbol: Trading symbol (e.g., BTC/USDT)
            data: Training data DataFrame
            
        Returns:
            bool: True if training successful
        """
        try:
            # Validate inputs
            if not self._validate_inputs(symbol, data):
                return False
            
            # Check if we have enough data
            if len(data) < self.min_samples_per_symbol:
                logger.warning(
                    f"âš ï¸ Insufficient data for {symbol}: {len(data)} < {self.min_samples_per_symbol}, "
                    f"will use global model"
                )
                return False
            
            # Acquire training lock
            with self._training_lock:
                logger.info(f"ðŸŽ“ Starting training for symbol: {symbol} with {len(data)} samples")
                
                # Prepare features and labels
                result = self._prepare_training_data(data)
                if result is None:
                    logger.error(f"âŒ Failed to prepare training data for {symbol}")
                    return False
                
                X, y = result
                
                # Validate prepared data
                if len(X) != len(y) or len(X) == 0:
                    logger.error(f"âŒ Invalid training data dimensions for {symbol}")
                    return False
                
                # Train model
                start_time = time.time()
                metadata = self.model_trainer.train_model(X, y)
                training_time = time.time() - start_time
                
                if metadata is None:
                    logger.error(f"âŒ Model training failed for {symbol}")
                    return False
                
                # Get trained model
                if self.model_trainer.current_model is None:
                    logger.error(f"âŒ No model created during training for {symbol}")
                    return False
                
                # Store model and metadata
                with self._lock:
                    self.models[symbol] = self.model_trainer.current_model
                    self.model_metadata[symbol] = {
                        'metadata': metadata,
                        'training_samples': len(X),
                        'training_time': training_time,
                        'last_trained': datetime.utcnow(),
                        'feature_names': list(X.columns) if hasattr(X, 'columns') else [],
                        'symbol': symbol
                    }
                    
                    # Initialize drift detector for this symbol
                    self._initialize_drift_detector(symbol, X)
                    
                    # Update prediction stats
                    self.prediction_stats[symbol] = {
                        'total_predictions': 0,
                        'successful_predictions': 0,
                        'avg_confidence': 0.0,
                        'last_prediction': None
                    }
                    
                    # Save to database if available
                    self._save_model_to_db(symbol, metadata, training_time)
                
                logger.success(
                    f"âœ… Successfully trained model for {symbol}\n"
                    f"   Samples: {len(X)}, Training time: {training_time:.2f}s\n"
                    f"   Test Accuracy: {metadata.get('metrics', {}).get('test_accuracy', 0):.2%}"
                )
                
                return True
                
        except Exception as e:
            logger.error(f"âŒ Failed to train model for {symbol}: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False
    
    def _validate_inputs(self, symbol: str, data: pd.DataFrame) -> bool:
        """Validate training inputs"""
        try:
            if not isinstance(symbol, str) or len(symbol.strip()) == 0:
                logger.error("âŒ Invalid symbol")
                return False
            
            if not isinstance(data, pd.DataFrame) or data.empty:
                logger.error("âŒ Invalid or empty DataFrame")
                return False
            
            # Check required columns
            required_cols = ['close', 'high', 'low', 'volume']
            missing_cols = [col for col in required_cols if col not in data.columns]
            if missing_cols:
                logger.error(f"âŒ Missing required columns: {missing_cols}")
                return False
            
            return True
        except Exception as e:
            logger.error(f"âŒ Input validation failed: {e}")
            return False
    
    def _prepare_training_data(self, data: pd.DataFrame) -> Optional[Tuple[pd.DataFrame, pd.Series]]:
        """Prepare features and labels for training"""
        try:
            # This is a simplified version - in practice, you'd want to:
            # 1. Generate signals/trades from historical data
            # 2. Extract features for each trade
            # 3. Create labels based on actual outcomes
            
            # For now, create dummy training data based on price movements
            if len(data) < 2:
                return None
            
            # Create features (this should be replaced with your actual feature engineering)
            features_list = []
            labels = []
            
            # Example: use rolling windows to create features and labels
            window_size = min(20, len(data) // 2)
            for i in range(window_size, len(data)):
                # Create a slice of data for feature extraction
                slice_df = data.iloc[i-window_size:i+1].copy()
                
                # Create a dummy signal
                signal = {
                    'side': 'BUY' if data.iloc[i]['close'] > data.iloc[i-1]['close'] else 'SELL',
                    'strength': 75,
                    'price': data.iloc[i]['close']
                }
                
                # Extract features
                features = feature_engineer.extract_features(slice_df, signal)
                if not features or not isinstance(features, dict):
                    continue
                
                # Create label (1 if next period price increases, 0 otherwise)
                if i < len(data) - 1:
                    next_price = data.iloc[i+1]['close']
                    current_price = data.iloc[i]['close']
                    label = 1 if next_price > current_price else 0
                    
                    features_list.append(features)
                    labels.append(label)
            
            if len(features_list) == 0:
                logger.warning("âš ï¸ No valid features extracted")
                return None
            
            # Convert to DataFrames
            X = pd.DataFrame(features_list)
            y = pd.Series(labels)
            
            # Handle missing values
            numeric_columns = X.select_dtypes(include=['number']).columns
            for col in numeric_columns:
                if X[col].isnull().any():
                    X[col] = X[col].fillna(X[col].median())
            
            # Remove any remaining NaN values
            mask = ~(X.isnull().any(axis=1) | y.isnull())
            X = X[mask]
            y = y[mask]
            
            if len(X) == 0:
                logger.error("âŒ No valid samples after cleaning")
                return None
            
            logger.info(f"ðŸ“Š Prepared {len(X)} training samples with {len(X.columns)} features")
            return X, y
            
        except Exception as e:
            logger.error(f"âŒ Failed to prepare training data: {e}")
            return None
    
    def _initialize_drift_detector(self, symbol: str, X: pd.DataFrame):
        """Initialize drift detector for symbol"""
        try:
            drift_detector = DataDriftDetector(threshold=0.05)
            # Use a sample of the training data as reference
            sample_size = min(1000, len(X))
            reference_data = X.sample(n=sample_size, random_state=42) if len(X) > sample_size else X
            if drift_detector.fit(reference_data):
                self.drift_detectors[symbol] = drift_detector
                logger.debug(f"âœ… Initialized drift detector for {symbol}")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to initialize drift detector for {symbol}: {e}")
    
    def _save_model_to_db(self, symbol: str, metadata: Dict, training_time: float):
        """Save model information to database"""
        try:
            if hasattr(self.db, 'register_model'):
                model_path = metadata.get('model_path', '')
                metrics = metadata.get('metrics', {})
                
                self.db.register_model(
                    model_type=getattr(ml_config, 'model_type', 'random_forest'),
                    model_name=f"per_symbol_{symbol}",
                    version="1.0",
                    model_path=model_path,
                    training_samples=metadata.get('n_samples', 0),
                    validation_score=metrics.get('test_accuracy', 0.0),
                    hyperparameters={'symbol': symbol},
                    feature_importance=metadata.get('feature_importance', {}),
                    symbol=symbol,
                    test_score=metrics.get('test_f1', 0.0),
                    training_duration_seconds=int(training_time),
                    model_size_mb=0.0  # You could calculate this
                )
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to save model to database: {e}")
    
    def get_model(self, symbol: str) -> Optional[Any]:
        """
        Get best model for symbol (symbol-specific or global fallback)
        
        Args:
            symbol: Trading symbol
            
        Returns:
            Model instance or None if no model available
        """
        try:
            if not isinstance(symbol, str):
                logger.error("âŒ Invalid symbol type")
                return None
            
            with self._lock:
                # Check if we have a symbol-specific model
                if symbol in self.models:
                    # Check if model needs retraining
                    if self._needs_retraining(symbol):
                        logger.info(f"ðŸ”„ Model for {symbol} needs retraining")
                        # In production, you might want to trigger async retraining here
                    
                    return self.models[symbol]
                
                # Fallback to global model
                if self.global_model is not None:
                    logger.debug(f"ðŸ” Using global model for {symbol} (no symbol-specific model)")
                    return self.global_model
                
                logger.warning(f"âš ï¸ No model available for {symbol} (not even global model)")
                return None
                
        except Exception as e:
            logger.error(f"âŒ Failed to get model for {symbol}: {e}")
            return None
    
    def _needs_retraining(self, symbol: str) -> bool:
        """Check if symbol model needs retraining based on drift or age"""
        try:
            # Don't check too frequently
            now = datetime.utcnow()
            last_check = self.last_retrain_check.get(symbol, None)
            if last_check and (now - last_check).total_seconds() < 3600:  # 1 hour
                return False
            
            self.last_retrain_check[symbol] = now
            
            # Check data drift if detector available
            if symbol in self.drift_detectors:
                # In practice, you'd want to pass recent data here
                # For now, just return False since we don't have live data
                pass
            
            # Check age-based retraining
            if symbol in self.model_metadata:
                metadata = self.model_metadata[symbol]
                last_trained = metadata.get('last_trained')
                if last_trained:
                    age_hours = (now - last_trained).total_seconds() / 3600
                    max_age_hours = getattr(ml_config, 'retrain_interval_hours', 24)
                    if age_hours > max_age_hours:
                        logger.info(f"ðŸ”„ Model for {symbol} is {age_hours:.1f} hours old (> {max_age_hours}h limit)")
                        return True
            
            return False
            
        except Exception as e:
            logger.error(f"âŒ Failed to check retraining need for {symbol}: {e}")
            return False
    
    def set_global_model(self, model: Any, metadata: Optional[Dict] = None):
        """Set global fallback model"""
        try:
            with self._lock:
                self.global_model = model
                self.global_metadata = metadata or {}
                logger.success("âœ… Global model set successfully")
        except Exception as e:
            logger.error(f"âŒ Failed to set global model: {e}")
    
    def get_model_info(self, symbol: str) -> Dict[str, Any]:
        """Get comprehensive information about a symbol's model"""
        try:
            with self._lock:
                info = {
                    'symbol': symbol,
                    'has_symbol_model': symbol in self.models,
                    'using_global_model': symbol not in self.models and self.global_model is not None,
                    'no_model_available': symbol not in self.models and self.global_model is None,
                    'last_updated': None,
                    'training_samples': 0,
                    'performance_metrics': {},
                    'feature_count': 0,
                    'needs_retraining': False
                }
                
                if symbol in self.models:
                    metadata = self.model_metadata.get(symbol, {})
                    info.update({
                        'last_updated': metadata.get('last_trained'),
                        'training_samples': metadata.get('training_samples', 0),
                        'performance_metrics': metadata.get('metadata', {}).get('metrics', {}),
                        'feature_count': len(metadata.get('feature_names', [])),
                        'needs_retraining': self._needs_retraining(symbol),
                        'training_time': metadata.get('training_time', 0)
                    })
                elif self.global_model:
                    info.update({
                        'last_updated': self.global_metadata.get('last_trained'),
                        'training_samples': self.global_metadata.get('training_samples', 0),
                        'performance_metrics': self.global_metadata.get('metrics', {}),
                        'feature_count': len(self.global_metadata.get('feature_names', [])),
                    })
                
                return info
                
        except Exception as e:
            logger.error(f"âŒ Failed to get model info for {symbol}: {e}")
            return {'error': str(e)}
    
    def get_all_models_info(self) -> Dict[str, Any]:
        """Get information about all managed models"""
        try:
            with self._lock:
                return {
                    'total_symbol_models': len(self.models),
                    'symbols': list(self.models.keys()),
                    'has_global_model': self.global_model is not None,
                    'prediction_stats': self.prediction_stats,
                    'configuration': {
                        'min_samples_per_symbol': self.min_samples_per_symbol,
                        'retrain_threshold': self.retrain_threshold,
                        'max_models': self.max_models
                    }
                }
        except Exception as e:
            logger.error(f"âŒ Failed to get all models info: {e}")
            return {'error': str(e)}
    
    def remove_symbol_model(self, symbol: str) -> bool:
        """Remove a symbol-specific model"""
        try:
            with self._lock:
                if symbol in self.models:
                    del self.models[symbol]
                    if symbol in self.model_metadata:
                        del self.model_metadata[symbol]
                    if symbol in self.drift_detectors:
                        del self.drift_detectors[symbol]
                    if symbol in self.prediction_stats:
                        del self.prediction_stats[symbol]
                    if symbol in self.last_retrain_check:
                        del self.last_retrain_check[symbol]
                    
                    logger.info(f"ðŸ—‘ï¸ Removed model for {symbol}")
                    return True
                else:
                    logger.warning(f"âš ï¸ No model found for {symbol}")
                    return False
                    
        except Exception as e:
            logger.error(f"âŒ Failed to remove model for {symbol}: {e}")
            return False
    
    def clear_all_models(self):
        """Clear all symbol-specific models"""
        try:
            with self._lock:
                count = len(self.models)
                self.models.clear()
                self.model_metadata.clear()
                self.drift_detectors.clear()
                self.prediction_stats.clear()
                self.last_retrain_check.clear()
                
                logger.info(f"ðŸ§¹ Cleared all {count} symbol models")
                
        except Exception as e:
            logger.error(f"âŒ Failed to clear all models: {e}")
    
    def update_prediction_stats(self, symbol: str, success: bool, confidence: float):
        """Update prediction statistics for monitoring"""
        try:
            with self._lock:
                if symbol not in self.prediction_stats:
                    self.prediction_stats[symbol] = {
                        'total_predictions': 0,
                        'successful_predictions': 0,
                        'avg_confidence': 0.0,
                        'last_prediction': datetime.utcnow()
                    }
                
                stats = self.prediction_stats[symbol]
                total = stats['total_predictions']
                current_avg = stats['avg_confidence']
                
                # Update moving average of confidence
                new_avg = ((current_avg * total) + confidence) / (total + 1)
                
                stats.update({
                    'total_predictions': total + 1,
                    'successful_predictions': stats['successful_predictions'] + (1 if success else 0),
                    'avg_confidence': new_avg,
                    'last_prediction': datetime.utcnow(),
                    'success_rate': (stats['successful_predictions'] + (1 if success else 0)) / (total + 1)
                })
                
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to update prediction stats: {e}")
    
    def get_prediction_stats(self, symbol: str) -> Dict[str, Any]:
        """Get prediction statistics for a symbol"""
        try:
            with self._lock:
                return self.prediction_stats.get(symbol, {}).copy()
        except Exception as e:
            logger.error(f"âŒ Failed to get prediction stats: {e}")
            return {}

# Global instance
_per_symbol_manager: Optional[PerSymbolModelManager] = None
_per_symbol_lock = threading.Lock()

def get_symbol_model_manager() -> PerSymbolModelManager:
    """Get global per-symbol model manager instance"""
    global _per_symbol_manager
    with _per_symbol_lock:
        if _per_symbol_manager is None:
            _per_symbol_manager = PerSymbolModelManager()
        return _per_symbol_manager

def reset_symbol_model_manager():
    """Reset global per-symbol model manager instance"""
    global _per_symbol_manager
    with _per_symbol_lock:
        if _per_symbol_manager:
            _per_symbol_manager.clear_all_models()
        _per_symbol_manager = None
        logger.info("ðŸ”„ Per-Symbol Model Manager reset")